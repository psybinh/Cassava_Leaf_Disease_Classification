{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "logical-employee",
   "metadata": {},
   "source": [
    "# Import"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "reduced-employer",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import timm\n",
    "import random\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision import models\n",
    "import tqdm\n",
    "from torch import nn\n",
    "from torch import optim\n",
    "\n",
    "import json\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "creative-height",
   "metadata": {},
   "source": [
    "# Set seed (Reproduce result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "continuing-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 123456789\n",
    "\n",
    "random.seed(SEED)\n",
    "np.random.seed(SEED)\n",
    "torch.manual_seed(SEED)\n",
    "torch.cuda.manual_seed(SEED)\n",
    "torch.backends.cudnn.deterministic = True"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "loaded-client",
   "metadata": {},
   "source": [
    "# Split data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "healthy-grace",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('cassava-leaf-disease-classification/train.csv')\n",
    "choosen_prob = np.random.rand(len(data))\n",
    "train_df = data[choosen_prob >= 0.9]\n",
    "val_df = data[choosen_prob < 0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "alert-belarus",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3    13158\n",
       "4     2577\n",
       "2     2386\n",
       "1     2189\n",
       "0     1087\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.label.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "rocky-intersection",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "val_df.label.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "thousand-internet",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df.label.value_counts().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-industry",
   "metadata": {},
   "source": [
    "# Hyper params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "moved-grain",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.4070720457073391, 0.20214130364727165, 0.18545151453641143, 0.03362876680984022, 0.1717063692991376]\n"
     ]
    }
   ],
   "source": [
    "EXP_NAME = 'exp_06'\n",
    "\n",
    "###########################################\n",
    "MODEL_NAME = 'tf_efficientnet_b3_ns'\n",
    "IM_SIZE = 300\n",
    "###########################################\n",
    "BATCH_SIZE = 32\n",
    "LEARNING_RATE = 1e-4\n",
    "LR_STEP = 10\n",
    "EPOCH = 50\n",
    "WARMUP_EPOCH = 50\n",
    "WEIGHT_DECAY = 1e-4\n",
    "GRADIENT_COEFF = 2\n",
    "WEIGHTS = None\n",
    "##########################################\n",
    "CLASS_NUM = [1087, 2189, 2386, 13158, 2577]\n",
    "WEIGHTS = [1 / weight for weight in CLASS_NUM]\n",
    "NORM_WEIGHTS = [weight / sum(WEIGHTS) for weight in WEIGHTS]\n",
    "# NORM_WEIGHTS = None\n",
    "print(NORM_WEIGHTS)\n",
    "##########################################\n",
    "VAL_BATCH_SIZE = BATCH_SIZE\n",
    "############################################\n",
    "NUM_WORKER = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "iraqi-australia",
   "metadata": {},
   "outputs": [],
   "source": [
    "HYPER_PARAMS = {\n",
    "    'EXP_NAME': EXP_NAME,\n",
    "\n",
    "    'MODEL_NAME': MODEL_NAME,\n",
    "    'IM_SIZE': IM_SIZE,\n",
    "\n",
    "    'BATCH_SIZE': BATCH_SIZE,\n",
    "    'LEARNING_RATE': LEARNING_RATE,\n",
    "    'LR_STEP': LR_STEP,\n",
    "    'EPOCH': EPOCH,\n",
    "    'WARMUP_EPOCH': WARMUP_EPOCH,\n",
    "    'WEIGHT_DECAY': WEIGHT_DECAY,\n",
    "    'NORM_WEIGHTS': NORM_WEIGHTS,\n",
    "\n",
    "    'VAL_BATCH_SIZE': VAL_BATCH_SIZE,\n",
    "\n",
    "    'NUM_WORKER': NUM_WORKER,\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "vocational-nothing",
   "metadata": {},
   "source": [
    "# Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "southern-belief",
   "metadata": {},
   "outputs": [],
   "source": [
    "mean = (0.485, 0.456, 0.406)\n",
    "std = (0.229, 0.224, 0.225)\n",
    "COLOR_JILTER = (0, 0.3)\n",
    "\n",
    "train_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((IM_SIZE, IM_SIZE), interpolation=Image.BICUBIC),\n",
    "     transforms.ColorJitter(brightness=COLOR_JILTER, contrast=COLOR_JILTER, saturation=COLOR_JILTER, hue=COLOR_JILTER),\n",
    "     transforms.RandomResizedCrop((IM_SIZE, IM_SIZE)),\n",
    "     transforms.RandomRotation(45),\n",
    "     transforms.RandomVerticalFlip(p=0.5),\n",
    "     transforms.RandomHorizontalFlip(p=0.5),\n",
    "     transforms.Normalize(mean, std)])\n",
    "\n",
    "val_transform = transforms.Compose(\n",
    "    [transforms.ToTensor(),\n",
    "     transforms.Resize((IM_SIZE, IM_SIZE), interpolation=Image.BICUBIC),\n",
    "     transforms.Normalize(mean, std)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ethical-universal",
   "metadata": {},
   "source": [
    "# Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "speaking-marijuana",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CassavaDataset(Dataset):\n",
    "    def __init__(self, image_dir, df, transform=None):\n",
    "        self.image_dir = image_dir\n",
    "        self.df = df.reset_index(drop=True)\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "    \n",
    "    def __getitem__(self, index):\n",
    "        row = self.df.loc[index]\n",
    "        label = row.label\n",
    "        image_name = row.image_id\n",
    "        \n",
    "        image = Image.open(os.path.join(self.image_dir, image_name))\n",
    "        image = np.array(image)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fabulous-pharmacy",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_image_dir = 'cassava-leaf-disease-classification/train_images'\n",
    "train_dataset = CassavaDataset(train_image_dir, train_df, transform=train_transform)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, \n",
    "                                           batch_size=BATCH_SIZE, \n",
    "                                           shuffle=True, \n",
    "                                           num_workers=NUM_WORKER)\n",
    "\n",
    "val_image_dir = 'cassava-leaf-disease-classification/train_images'\n",
    "val_dataset = CassavaDataset(val_image_dir, val_df, transform=val_transform)\n",
    "val_loader = torch.utils.data.DataLoader(val_dataset, \n",
    "                                           batch_size=VAL_BATCH_SIZE, \n",
    "                                           shuffle=False, \n",
    "                                           num_workers=NUM_WORKER)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "swedish-shareware",
   "metadata": {},
   "source": [
    "# Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "backed-convertible",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\")\n",
    "model = timm.create_model(MODEL_NAME, pretrained=True, num_classes=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "finished-audience",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Convert model to CUDA\n"
     ]
    }
   ],
   "source": [
    "class_weights = None\n",
    "if NORM_WEIGHTS != None:\n",
    "    class_weights = torch.FloatTensor(NORM_WEIGHTS).cuda()\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss(weight=class_weights)\n",
    "linear_scaled_lr = 8.0 * LEARNING_RATE * GRADIENT_COEFF * BATCH_SIZE / 512.0\n",
    "# optimizer = optim.SGD(model.parameters(), lr=linear_scaled_lr, momentum=0.9, weight_decay=WEIGHT_DECAY)\n",
    "optimizer = optim.Adam(model.parameters(), lr=linear_scaled_lr, weight_decay=WEIGHT_DECAY)\n",
    "lr_scheduler = optim.lr_scheduler.StepLR(optimizer, step_size=LR_STEP)\n",
    "model.cuda()\n",
    "print('Convert model to CUDA')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "front-crisis",
   "metadata": {},
   "source": [
    "# Train and Val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "designed-volume",
   "metadata": {},
   "outputs": [],
   "source": [
    "def freeze_bn(model):\n",
    "    model.eval()\n",
    "    model.classifier.train()\n",
    "    model.conv_head.train()\n",
    "    model.bn2.train()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dressed-trinity",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_one_epoch(epoch, model, train_loader, criterion, optimizer, finetune_on_bn=True, logs_file=None):\n",
    "    if finetune_on_bn == False:\n",
    "        freeze_bn(model)\n",
    "    else:\n",
    "        model.train()\n",
    "        \n",
    "    running_loss = 0.0\n",
    "    scaler = torch.cuda.amp.GradScaler()\n",
    "    for i, data in enumerate(tqdm.tqdm(train_loader), 0):\n",
    "        inputs, labels = data\n",
    "        with torch.cuda.amp.autocast():\n",
    "            inputs = inputs.cuda()\n",
    "            labels = labels.cuda()\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            assert outputs.dtype is torch.float16\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss = loss / GRADIENT_COEFF\n",
    "            assert loss.dtype is torch.float32\n",
    "        \n",
    "        scaler.scale(loss).backward()\n",
    "#         scaler.unscale_(optimizer)\n",
    "#         torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm)\n",
    "        \n",
    "        if (i + 1) % GRADIENT_COEFF == 0:\n",
    "            scaler.step(optimizer)\n",
    "            scaler.update()\n",
    "            optimizer.zero_grad()\n",
    "            running_loss += loss.item()\n",
    "            \n",
    "            if logs_file != None:\n",
    "                logs_file.write('Training loss at epoch {}, iteration {}: {}\\n'.format(epoch, i, running_loss / i * GRADIENT_COEFF))\n",
    "    if logs_file != None:\n",
    "        logs_file.write('------------------------------------------------\\n')\n",
    "           \n",
    "    return running_loss / len(train_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "southeast-skating",
   "metadata": {},
   "outputs": [],
   "source": [
    "def validate(epoch, model, val_loader, logs_file=None):\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        for data in tqdm.tqdm(val_loader):\n",
    "            images, labels = data\n",
    "            images = images.cuda()\n",
    "            labels = labels.cuda()\n",
    "        \n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "            \n",
    "            running_loss += loss.item()\n",
    "    \n",
    "    if logs_file != None:\n",
    "        logs_file.write('Validating loss at epoch {}: {}\\n'.format(epoch, running_loss / len(val_loader)))\n",
    "        logs_file.write('Validating accuracy at epoch {}: {}\\n'.format(epoch, correct / total))\n",
    "        logs_file.write('**************************************************\\n')\n",
    "        \n",
    "    torch.save(model.state_dict(), 'models/exp_{}_time_{}_epoch_{}_acc_{}.pth'.format(EXP_NAME, int(time.time()), epoch, correct / total))\n",
    "    return running_loss / len(val_loader), correct / total\n",
    "\n",
    "# def frezze_top(Model):\n",
    "#     pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "little-quarterly",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 47%|████▋     | 33/70 [00:38<00:31,  1.17it/s]"
     ]
    }
   ],
   "source": [
    "import time\n",
    "\n",
    "train_loss_list = []\n",
    "val_acc_list = []\n",
    "val_loss_list = []\n",
    "with open('logs/logs_{}_{}.txt'.format(EXP_NAME, int(time.time())), 'w') as logs_file:\n",
    "    logs_file.write(json.dumps(HYPER_PARAMS))\n",
    "    logs_file.write('\\n')\n",
    "    logs_file.write('**************************************************\\n')\n",
    "    \n",
    "    for epoch in range(EPOCH):\n",
    "        train_loss = 0.0\n",
    "        if epoch < WARMUP_EPOCH:\n",
    "            train_loss = train_one_epoch(epoch, \n",
    "                                         model, \n",
    "                                         train_loader, \n",
    "                                         criterion, \n",
    "                                         optimizer, \n",
    "                                         finetune_on_bn=False, \n",
    "                                         logs_file=logs_file)\n",
    "        else:\n",
    "            train_loss = train_one_epoch(epoch, \n",
    "                                         model, \n",
    "                                         train_loader, \n",
    "                                         criterion, \n",
    "                                         optimizer, \n",
    "                                         logs_file=logs_file)\n",
    "        val_loss, val_acc = validate(epoch, \n",
    "                                     model, \n",
    "                                     val_loader, \n",
    "                                  \n",
    "                                     logs_file=logs_file)\n",
    "\n",
    "        print('Train loss: {}'.format(train_loss))\n",
    "        print('Val loss: {}'.format(val_loss))\n",
    "        print('Val acc: {}'.format(val_acc))\n",
    "        \n",
    "        train_loss_list.append(train_loss)\n",
    "        val_acc_list.append(val_acc)\n",
    "        val_loss_list.append(val_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "charitable-rachel",
   "metadata": {},
   "source": [
    "# Visualize train loss and val loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "continued-stuff",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "print(train_loss_list)\n",
    "print(val_acc_list)\n",
    "print(val_loss_list)\n",
    "\n",
    "plt.plot(train_loss_list)\n",
    "plt.plot(val_acc_list)\n",
    "plt.plot(val_loss_list)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "minute-remedy",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
